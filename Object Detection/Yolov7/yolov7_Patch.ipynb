{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pimpisaNga555/DADS7202_Project/blob/main/Object%20Detection/Yolov7/yolov7_Patch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBhTRIseceim",
        "outputId": "745f5512-bb9d-491c-f8b3-793cf85615ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1127, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 1127 (delta 12), reused 14 (delta 4), pack-reused 1098\u001b[K\n",
            "Receiving objects: 100% (1127/1127), 69.96 MiB | 30.38 MiB/s, done.\n",
            "Resolving deltas: 100% (522/522), done.\n",
            "/content/yolov7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (2.25.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (1.7.3)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (0.14.0+cu116)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (4.64.1)\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 14)) (3.19.6)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 17)) (2.9.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 21)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 22)) (0.11.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 34)) (7.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 35)) (5.4.8)\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (4.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.51.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.38.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2022.7)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 34)) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->-r requirements.txt (line 34)) (0.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.18.2 thop-0.1.1.post2209072238\n"
          ]
        }
      ],
      "source": [
        "# Download YOLOv7 repository and install requirements\n",
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "%cd yolov7\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPk8Rj_RdKzO",
        "outputId": "dcc98a52-3173-4710-ac54-298563a171f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "--2023-01-04 06:36:42--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230104%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230104T063642Z&X-Amz-Expires=300&X-Amz-Signature=6a04e00f80e62ca2db357916b5104f1cc3470909ccf9e6bb5b5c9592466408dc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-01-04 06:36:42--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230104%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230104T063642Z&X-Amz-Expires=300&X-Amz-Signature=6a04e00f80e62ca2db357916b5104f1cc3470909ccf9e6bb5b5c9592466408dc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75628875 (72M) [application/octet-stream]\n",
            "Saving to: ‘yolov7_training.pt’\n",
            "\n",
            "yolov7_training.pt  100%[===================>]  72.12M  14.1MB/s    in 5.3s    \n",
            "\n",
            "2023-01-04 06:36:48 (13.6 MB/s) - ‘yolov7_training.pt’ saved [75628875/75628875]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download trained weights\n",
        "%cd /content/yolov7\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pre-train"
      ],
      "metadata": {
        "id": "5JXtEMuhT5y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train1.py --batch 16 --cfg cfg/training/yolov7.yaml --epochs 1 --data /content/yolov7/project-1/data.yaml --weights 'yolov7.pt' --device 0 --name /content/drive/MyDrive/project_deep/check01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0twO7CukZ3u",
        "outputId": "22795a75-c401-4b10-c6e1-a949000fe508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7.yaml', data='/content/yolov7/project-1/data.yaml', device='0', entity=None, epochs=1, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='/content/drive/MyDrive/project_deep/check01', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='/content/drive/MyDrive/project_deep/check01', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, v5_metric=False, weights='yolov7.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     34156  models.yolo.IDetect                     [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37196556 parameters, 37196556 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 552/566 items from yolov7.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'project-1/train/labels' images and labels... 1553 found, 0 missing, 3 empty, 0 corrupted: 100% 1553/1553 [00:00<00:00, 3599.18it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: project-1/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'project-1/valid/labels.cache' images and labels... 148 found, 0 missing, 0 empty, 1 corrupted: 100% 148/148 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.66, Best Possible Recall (BPR) = 0.9976\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to /content/drive/MyDrive/project_deep/check01\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/0     7.78G   0.07313   0.01499         0   0.08812        15       640: 100% 98/98 [01:57<00:00,  1.20s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 5/5 [00:18<00:00,  3.71s/it]\n",
            "                 all         147         445       0.357       0.283       0.211      0.0829\n",
            "1 epochs completed in 0.041 hours.\n",
            "\n",
            "Optimizer stripped from /content/drive/MyDrive/project_deep/check01/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from /content/drive/MyDrive/project_deep/check01/weights/best.pt, 74.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pre-train (train 1 epochs)\n",
        "!python test.py --data /content/yolov7/project-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "id": "diXCPPCoT-3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dabc24ac-153b-4930-98dc-029b553eb658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/project-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'project-1/valid/labels.cache' images and labels... 148 found, 0 missing, 0 empty, 1 corrupted: 100% 148/148 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.33it/s]\n",
            "                 all         147         445       0.336       0.281       0.205      0.0806\n",
            "Speed: 15.0/1.7/16.8 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test \n"
      ],
      "metadata": {
        "id": "pjPAyTORf-32"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GrsVEa6TfGq",
        "outputId": "975c489f-78c9-4389-e431-a1aa0335fcd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.001, data='/content/yolov7/project-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "Scanning images:   0% 0/148 [00:00<?, ?it/s]\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label project-1/valid/images/COCO_train2014_000000099844_jpg.rf.052abd925bf67e6a6e92edf158fdc219.jpg: duplicate labels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'project-1/valid/labels' images and labels... 148 found, 0 missing, 0 empty, 1 corrupted: 100% 148/148 [00:00<00:00, 2713.83it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: project-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:05<00:00,  1.81it/s]\n",
            "                 all         147         445       0.621       0.604       0.605       0.337\n",
            "Speed: 14.2/2.4/16.6 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp\n"
          ]
        }
      ],
      "source": [
        "#Run test\n",
        "!python test.py --data /content/yolov7/project-1/data.yaml --img 640 --batch 16 --conf 0.001 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7VLiBjunecT"
      },
      "source": [
        "Add Patch center"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UocFOTZ5qbdw",
        "outputId": "479cb91a-77a7-4342-f8b2-978a9d3d55be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.8/dist-packages (0.2.22)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.21.6)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (7.1.2)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.7)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.6.0.66)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2022.12.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.15.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.21.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: urllib3==1.26.6 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.26.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.25.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.64.1)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in projectCar-1 to yolov7pytorch: 100% [22253397 / 22253397] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to projectCar-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1336.29it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add patch center)\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"projectcar\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pre-Train (Test)"
      ],
      "metadata": {
        "id": "SeVjWbGlpeam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run pre-train (add patch center)\n",
        "!python test.py --data /content/drive/MyDrive/CarPatch/projectCar-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEwTliGtonIV",
        "outputId": "2d2ada3a-ed1f-4674-c9f9-3093440c5b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/drive/MyDrive/CarPatch/projectCar-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'projectCar-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3542.19it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: projectCar-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.81it/s]\n",
            "                 all         287         903       0.281       0.205       0.129      0.0445\n",
            "Speed: 13.7/1.7/15.5 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4xvu4F5oyR-",
        "outputId": "0c12a25c-0c50-4d3b-9fda-d33f5bdb063c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/drive/MyDrive/CarPatch/projectCar-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'projectCar-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3342.59it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: projectCar-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.92it/s]\n",
            "                 all         287         903       0.697       0.472       0.515       0.333\n",
            "Speed: 13.1/1.5/14.5 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp6\n"
          ]
        }
      ],
      "source": [
        "#Run trained (add patch center)\n",
        "!python test.py --data /content/drive/MyDrive/CarPatch/projectCar-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7LYQXP0rslP"
      },
      "source": [
        "#Add Circle Patch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import data (add circle patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carcircle\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ],
      "metadata": {
        "id": "cz-HeVX_TOQz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "139c26a2-10cf-4747-b95f-c9dcf914c457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Carcircle-1 to yolov7pytorch: 100% [22055888 / 22055888] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Carcircle-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1833.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run pre-train (add circle patch)\n",
        "!python test.py --data /content/yolov7/Carcircle-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9yz52dQpnZO",
        "outputId": "3e47004f-f66a-4a52-e374-d361ff2cdda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/Carcircle-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Carcircle-1/valid/labels.cache' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.72it/s]\n",
            "                 all         287         903       0.371       0.235       0.182      0.0649\n",
            "Speed: 13.8/1.7/15.5 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdC682eUrgHF",
        "outputId": "dba908e5-6d70-4bb8-d85c-5aabf2d325fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/Carcircle-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Carcircle-1/valid/labels.cache' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.74it/s]\n",
            "                 all         287         903       0.694       0.602       0.623       0.389\n",
            "Speed: 14.2/1.6/15.7 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp13\n"
          ]
        }
      ],
      "source": [
        "#Run trained (add circle patch)\n",
        "!python test.py --data /content/yolov7/Carcircle-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaerFsFLsIYN"
      },
      "source": [
        "#Add Down Patch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uYPUzbqslN9"
      },
      "source": [
        "5 % Down Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEyQrAc0sl3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29475b80-ac19-43d8-867f-4e36dceb812f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in cardown-1 to yolov7pytorch: 100% [22274468 / 22274468] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to cardown-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 2661.88it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add down patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"cardown\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run pre-train (add down patch)\n",
        "!python test.py --data /content/yolov7/cardown-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ERHPfL4qCMt",
        "outputId": "56f639aa-9a2b-43bb-8d0f-69756c5e0522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardown-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardown-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3138.32it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardown-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.78it/s]\n",
            "                 all         287         903       0.293       0.235       0.149      0.0493\n",
            "Speed: 14.2/1.4/15.6 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8QfAxmGsmAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "616e54da-94fa-458c-9eb1-6684ab6b568e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardown-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardown-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3247.85it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardown-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:07<00:00,  2.31it/s]\n",
            "                 all         287         903       0.779       0.596       0.683        0.41\n",
            "Speed: 13.9/1.7/15.6 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp\n"
          ]
        }
      ],
      "source": [
        "#Run trained (add down patch)\n",
        "!python test.py --data /content/yolov7/cardown-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hQX98upsQ0d"
      },
      "source": [
        "10 % Down Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDK4kn_Friku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9b5739-49a7-4a29-a299-f180b2667ada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in cardown10-1 to yolov7pytorch: 100% [22283237 / 22283237] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to cardown10-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1626.58it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add down patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"cardown10\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add down patch)\n",
        "!python test.py --data /content/yolov7/cardown10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqWdpE1WqDfO",
        "outputId": "7090074f-b6f2-4499-c37d-d0dea550cd6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardown10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardown10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3562.91it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardown10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.69it/s]\n",
            "                 all         287         903       0.286       0.297       0.172      0.0597\n",
            "Speed: 14.4/1.4/15.8 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfCncgoLriqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd9b366-4296-494e-b7e4-b3291348a1a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardown10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardown10-1/valid/labels.cache' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.68it/s]\n",
            "                 all         287         903       0.762       0.703        0.75       0.462\n",
            "Speed: 13.8/1.8/15.6 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp4\n"
          ]
        }
      ],
      "source": [
        "#run trained (add down patch)\n",
        "!python test.py --data /content/yolov7/cardown10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CT5pihksiAY"
      },
      "source": [
        "15 % Down Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNA3zeyxrixX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf8307c-57be-4d8b-a6ce-0aa9b5e92d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in cardown15-1 to yolov7pytorch: 100% [22279927 / 22279927] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to cardown15-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 2166.91it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add down patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"cardown15\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add down patch)\n",
        "!python test.py --data /content/yolov7/cardown15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dDah5VsqGpd",
        "outputId": "e4f00ee0-5b7f-4484-f7d1-45a1802246bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardown15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardown15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3536.88it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardown15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.76it/s]\n",
            "                 all         287         903       0.286       0.315       0.187       0.069\n",
            "Speed: 14.1/1.6/15.7 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0oT8j3sri0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0151642-ce17-479a-aec5-88bd7daa8809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardown15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardown15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3361.95it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardown15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.79it/s]\n",
            "                 all         287         903       0.839         0.7       0.784       0.499\n",
            "Speed: 13.8/1.5/15.3 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp5\n"
          ]
        }
      ],
      "source": [
        "#run trained (add down patch)\n",
        "!python test.py --data /content/yolov7/cardown15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xaCY0pus1Xp"
      },
      "source": [
        "#Add Down Left Patch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVHuhEkps1HE"
      },
      "source": [
        "5 % Down Left Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-j_guj-ri9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "369375ce-4e64-4a40-c8ab-35d5259d6a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in cardownleft5-1 to yolov7pytorch: 100% [22278876 / 22278876] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to cardownleft5-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1424.58it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add down left patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"cardownleft5\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add down left patch)\n",
        "!python test.py --data /content/yolov7/cardownleft5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGD5NzeDqIJX",
        "outputId": "230a181b-299f-487b-c18e-888a2cd8b9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardownleft5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardownleft5-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3263.11it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardownleft5-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.72it/s]\n",
            "                 all         287         903        0.26       0.275       0.163      0.0532\n",
            "Speed: 14.6/1.7/16.3 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRCJWEyKrjAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a2c5e1-fd8c-4056-d484-34795ea43533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardownleft5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardownleft5-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3191.82it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardownleft5-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.76it/s]\n",
            "                 all         287         903        0.79       0.597       0.681       0.402\n",
            "Speed: 13.3/1.7/15.0 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp7\n"
          ]
        }
      ],
      "source": [
        "#run trained (add down left patch)\n",
        "!python test.py --data /content/yolov7/cardownleft5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp8rHjXztUnQ"
      },
      "source": [
        "10 % Down Left Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlRlV6qlrjG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27778925-762e-49d2-ab39-a7012fbd2cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in cardownleft10-1 to yolov7pytorch: 100% [22289737 / 22289737] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to cardownleft10-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1415.75it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add down left patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"cardownleft10\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add down left patch)\n",
        "!python test.py --data /content/yolov7/cardownleft10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7WGU1DmqJnt",
        "outputId": "7901de9a-55ac-46eb-fb06-b72c0a3e21a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardownleft10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardownleft10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3344.68it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardownleft10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.76it/s]\n",
            "                 all         287         903       0.299       0.307       0.184      0.0646\n",
            "Speed: 14.3/1.6/15.9 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwQlRCyorjJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cebf6042-1414-4a28-e030-2ad908a41fea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardownleft10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.8, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardownleft10-1/valid/labels.cache' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.68it/s]\n",
            "                 all         287         903       0.809       0.681        0.75       0.464\n",
            "Speed: 13.9/1.7/15.6 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp9\n"
          ]
        }
      ],
      "source": [
        "#run trained (add down left patch)\n",
        "!python test.py --data /content/yolov7/cardownleft10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.80 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUdeAQXytcKE"
      },
      "source": [
        "15 % Down Left Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DkY4kqEtbiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe6ff16-f13c-40ca-9dad-39922de39390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in cardownleft15-1 to yolov7pytorch: 100% [22285784 / 22285784] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to cardownleft15-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1812.13it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add down left patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"cardownleft15\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add down left patch)\n",
        "!python test.py --data /content/yolov7/cardownleft15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apeh4ihvqLF1",
        "outputId": "0fa260a6-61fc-43b2-e715-7d367d09119d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardownleft15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardownleft15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 2241.41it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardownleft15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:07<00:00,  2.55it/s]\n",
            "                 all         287         903       0.312       0.319       0.199      0.0719\n",
            "Speed: 14.8/1.7/16.6 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-dRZh28rjQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0eff1b8-864f-42cc-f3cc-39b86242bee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardownleft15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardownleft15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3362.34it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardownleft15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.69it/s]\n",
            "                 all         287         903       0.828       0.714       0.781       0.496\n",
            "Speed: 14.3/1.6/15.8 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp10\n"
          ]
        }
      ],
      "source": [
        "#run trained (add down left patch)\n",
        "!python test.py --data /content/yolov7/cardownleft15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjGmfDPxth_V"
      },
      "source": [
        "#Add Down Right Patch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT3vfrNetjIk"
      },
      "source": [
        "5 % Down Right Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRyDwQqcrjWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969fe2ad-16c3-4a12-8f90-c58d1042395f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in cardownRight5-1 to yolov7pytorch: 100% [22268226 / 22268226] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to cardownRight5-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1618.40it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add down right patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"cardownright5\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add down right patch)\n",
        "!python test.py --data /content/yolov7/cardownRight5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1h60UZRqMfF",
        "outputId": "03751892-7e1b-4cbf-a1ac-3a5075c6e55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardownRight5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardownRight5-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 2121.28it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardownRight5-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.62it/s]\n",
            "                 all         287         903       0.298       0.246       0.155       0.053\n",
            "Speed: 14.0/1.5/15.5 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fMPhGDErjaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8e8530-c2bc-4207-a777-f36f85b680a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardownRight5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardownRight5-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3545.04it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardownRight5-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.78it/s]\n",
            "                 all         287         903       0.787       0.632        0.71       0.435\n",
            "Speed: 13.7/1.4/15.2 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp11\n"
          ]
        }
      ],
      "source": [
        "#run trained (add down right patch)\n",
        "!python test.py --data /content/yolov7/cardownRight5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihoK2hU-tuvE"
      },
      "source": [
        "10 % Down Right Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a7E5FUMrjgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06eafcc7-0344-43f2-9f47-1415cc02234b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in cardownRight10-1 to yolov7pytorch: 100% [22265140 / 22265140] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to cardownRight10-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 833.62it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add down right patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"cardownright10\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add down right patch)\n",
        "!python test.py --data /content/yolov7/cardownRight10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB8sh0BiqNu3",
        "outputId": "a63ebacd-f50b-4b07-8bbe-6c4b346a2064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardownRight10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardownRight10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3280.23it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardownRight10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.78it/s]\n",
            "                 all         287         903       0.311       0.307       0.182      0.0651\n",
            "Speed: 14.4/1.4/15.8 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_MIC3fxrjjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d03242-8978-41a6-a662-9269f98531ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardownRight10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardownRight10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3359.16it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardownRight10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.69it/s]\n",
            "                 all         287         903       0.821         0.7       0.773       0.491\n",
            "Speed: 14.1/1.4/15.5 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp12\n"
          ]
        }
      ],
      "source": [
        "#run trained (add down right patch)\n",
        "!python test.py --data /content/yolov7/cardownRight10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAbA4dWwt0p9"
      },
      "source": [
        "15 % Down Right Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSadJmsetzoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd4fec4-d84e-455c-a97d-f10fa855f1c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in cardownRight15-1 to yolov7pytorch: 100% [22246402 / 22246402] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to cardownRight15-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1888.06it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add down right patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"cardownright15\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add down right patch)\n",
        "!python test.py --data /content/yolov7/cardownRight15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g3gNruOqPG1",
        "outputId": "a9ef2750-150f-429c-ef15-23b24fbff046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardownRight15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardownRight15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3317.61it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardownRight15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.72it/s]\n",
            "                 all         287         903       0.311       0.322       0.204      0.0758\n",
            "Speed: 14.1/1.5/15.5 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX6kxinytzli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ca7b00-75ed-4719-94aa-d1caeac2083e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/cardownRight15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cardownRight15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3383.84it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cardownRight15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.72it/s]\n",
            "                 all         287         903       0.832       0.724       0.799       0.512\n",
            "Speed: 13.8/1.6/15.3 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp13\n"
          ]
        }
      ],
      "source": [
        "#run trained (add down right patch)\n",
        "!python test.py --data /content/yolov7/cardownRight15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_BiA7yjt4wj"
      },
      "source": [
        "#Add Left Patch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak4KyW8rt4bG"
      },
      "source": [
        "5 % left Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8jCv0fXt359",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0839f397-b22e-4d26-ccb0-6957a1195068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in left5-1 to yolov7pytorch: 100% [22258227 / 22258227] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to left5-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1249.46it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add left patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"left5\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add left patch)\n",
        "!python test.py --data /content/yolov7/left5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMQv1ZVoqQo1",
        "outputId": "a0840dd9-58d3-4325-9a5b-db4b928858a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/left5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'left5-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3294.42it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: left5-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.79it/s]\n",
            "                 all         287         903       0.278       0.234       0.136      0.0464\n",
            "Speed: 14.1/1.5/15.6 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnV7PFrRtzfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19c3903-c167-43f5-844f-2411d097e84a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/left5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'left5-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3536.62it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: left5-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.72it/s]\n",
            "                 all         287         903       0.679       0.499       0.524       0.326\n",
            "Speed: 13.8/1.6/15.3 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp14\n"
          ]
        }
      ],
      "source": [
        "#run trained (add left patch)\n",
        "!python test.py --data /content/yolov7/left5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWsSBG4IuH9N"
      },
      "source": [
        "10 % left Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXSsVKu2tzXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e98f59d7-7ddb-4542-9d88-8b3a5cbcd5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in left10-1 to yolov7pytorch: 100% [22262960 / 22262960] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to left10-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1121.52it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add left patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"left10\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add left patch)\n",
        "!python test.py --data /content/yolov7/left10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLHQyEzaqR8e",
        "outputId": "87ee8ba5-b389-4517-c246-f6a23267624a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/left10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'left10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3266.92it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: left10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.73it/s]\n",
            "                 all         287         903       0.296       0.245       0.159      0.0538\n",
            "Speed: 14.2/1.5/15.7 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utz55hPVrjph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17d35692-bec5-4809-acb2-9a732434ac21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/left10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'left10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3473.66it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: left10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.79it/s]\n",
            "                 all         287         903       0.758       0.516       0.579        0.36\n",
            "Speed: 13.7/1.6/15.4 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp15\n"
          ]
        }
      ],
      "source": [
        "#run trained (add left patch)\n",
        "!python test.py --data /content/yolov7/left10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPNKweKvuMp9"
      },
      "source": [
        "15 % left Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nHsyW8juMDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18868617-b4cb-4c59-d5f9-7d9e27f5004f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carleft15-1 to yolov7pytorch: 100% [22265880 / 22265880] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carleft15-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1653.92it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add left patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carleft15\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add left patch)\n",
        "!python test.py --data /content/yolov7/carleft15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX9JPGWlqTkV",
        "outputId": "4a90b39b-a6a4-4693-d060-3b03c356db1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carleft15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carleft15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3392.24it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carleft15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.76it/s]\n",
            "                 all         287         903       0.381       0.221       0.165      0.0596\n",
            "Speed: 14.3/1.6/15.9 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgZ2OQDyuL_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e47c56-ef70-4aea-f894-87a9c7756deb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carleft15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carleft15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3365.11it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carleft15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.69it/s]\n",
            "                 all         287         903       0.734       0.565       0.614       0.382\n",
            "Speed: 13.8/1.8/15.6 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp16\n"
          ]
        }
      ],
      "source": [
        "#run trained (add left patch)\n",
        "!python test.py --data /content/yolov7/carleft15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zumy0nIauQJR"
      },
      "source": [
        "#Add Right Patch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK8eXbKVuPvl"
      },
      "source": [
        "5 % Right Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w9MAHN3uL4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85bc36d1-78af-4e7f-a554-1866a5699b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carright5-1 to yolov7pytorch: 100% [22250177 / 22250177] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carright5-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1869.37it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add right patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carright5\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add right patch)\n",
        "!python test.py --data /content/yolov7/carright5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD-K_f6AqVI9",
        "outputId": "3976bf36-addf-46e6-da1a-0c553fd84f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carright5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carright5-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3449.87it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carright5-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.71it/s]\n",
            "                 all         287         903       0.286       0.217       0.141      0.0455\n",
            "Speed: 14.5/1.5/16.0 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPcu7NDYuL07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7097efef-7315-44f0-fed5-802f28ac3528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carright5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carright5-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3404.53it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carright5-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.71it/s]\n",
            "                 all         287         903       0.729       0.558        0.61       0.378\n",
            "Speed: 13.9/1.7/15.5 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp17\n"
          ]
        }
      ],
      "source": [
        "#run trained (add right patch)\n",
        "!python test.py --data /content/yolov7/carright5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3iVE4t9uaTn"
      },
      "source": [
        "10 % Right Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "io0fESNPuLr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68c200c6-0ae2-4d0f-d892-851ec8747428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carright10-1 to yolov7pytorch: 100% [22241368 / 22241368] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carright10-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1684.66it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add right patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carright10\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add right patch)\n",
        "!python test.py --data /content/yolov7/carright10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bduvi-CZqXLF",
        "outputId": "ed2297e5-8d99-4588-fb5d-f479129f32ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carright10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carright10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3475.23it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carright10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.69it/s]\n",
            "                 all         287         903       0.265       0.262       0.162      0.0536\n",
            "Speed: 14.4/1.6/16.0 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1Ud88f7uLo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016f523e-200f-444c-f8fa-b5b51689f89d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carright10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carright10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3476.27it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carright10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.66it/s]\n",
            "                 all         287         903        0.73       0.602        0.65       0.408\n",
            "Speed: 14.3/1.7/16.0 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp18\n"
          ]
        }
      ],
      "source": [
        "#run trained (add right patch)\n",
        "!python test.py --data /content/yolov7/carright10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od0mRGoaudn0"
      },
      "source": [
        "15 % Right Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvS8-t6XuLiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab8ad6f-3d48-47bd-e091-d046b727a693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carright15-1 to yolov7pytorch: 100% [22229565 / 22229565] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carright15-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1570.10it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add right patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carright15\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add right patch)\n",
        "!python test.py --data /content/yolov7/carright15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSX_T5VtqYgu",
        "outputId": "6c33a861-bd11-44fe-a029-4a64bb2ee33b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carright15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carright15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3511.02it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carright15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.74it/s]\n",
            "                 all         287         903       0.283       0.256       0.169      0.0578\n",
            "Speed: 14.3/1.5/15.8 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fpqf7V3juLds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0801fd65-05a6-4c64-c54d-55a23e8dde01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carright15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carright15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3509.76it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carright15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.70it/s]\n",
            "                 all         287         903        0.72       0.649       0.671       0.424\n",
            "Speed: 14.5/1.6/16.1 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp19\n"
          ]
        }
      ],
      "source": [
        "#run trained (add right patch)\n",
        "!python test.py --data /content/yolov7/carright15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqLfAfITuiXs"
      },
      "source": [
        "#Add S Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnitbEJKugpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "989364e4-90a7-46e6-c5a6-7fc92ce7a38e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carS-1 to yolov7pytorch: 100% [21886761 / 21886761] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carS-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1201.62it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add s patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"cars-46ibf\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add s patch)\n",
        "!python test.py --data /content/yolov7/carS-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juG4JRfeqZy_",
        "outputId": "b2add158-2496-4389-f7be-02bc957b30cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carS-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carS-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3277.04it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carS-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:07<00:00,  2.37it/s]\n",
            "                 all         287         903        0.34       0.276       0.205      0.0766\n",
            "Speed: 14.6/2.1/16.7 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcnES26dugl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc4a98a-9739-4b62-f5b0-9ae5d32ceabd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carS-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carS-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3303.47it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carS-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.70it/s]\n",
            "                 all         287         903       0.666       0.661       0.662       0.415\n",
            "Speed: 14.5/1.6/16.1 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp20\n"
          ]
        }
      ],
      "source": [
        "#run trained (add s patch)\n",
        "!python test.py --data /content/yolov7/carS-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dpove0bu3nc"
      },
      "source": [
        "#Add Up Right Patch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lFbNy7CvAb9"
      },
      "source": [
        "5 % Up Right Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlRccbJqu3Oe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9ea768-315f-41fa-9512-0dc42e828497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carupRight5-1 to yolov7pytorch: 100% [22242423 / 22242423] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carupRight5-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1734.45it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add up right patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carupright5\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add up right patch)\n",
        "!python test.py --data /content/yolov7/carupRight5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWxcKbEXqbZN",
        "outputId": "8deaca80-6fdc-4c00-f6b5-98160b0dda9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carupRight5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carupRight5-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3587.89it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carupRight5-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.69it/s]\n",
            "                 all         287         903       0.275       0.269       0.163      0.0555\n",
            "Speed: 14.8/1.6/16.4 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDbv0Y4Vu2-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b4cf14-3f50-4c91-8377-5f9c52d22397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carupRight5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carupRight5-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3210.25it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carupRight5-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:08<00:00,  2.18it/s]\n",
            "                 all         287         903       0.763       0.555       0.626       0.393\n",
            "Speed: 14.4/2.1/16.6 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp24\n"
          ]
        }
      ],
      "source": [
        "#run trained (add up right patch)\n",
        "!python test.py --data /content/yolov7/carupRight5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSHwCDS8vKjB"
      },
      "source": [
        "10 % Up Right Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58Ax2tkKu26V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e609d96a-f4ba-4ed9-aa74-5cc9e38fd473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carupRight10-1 to yolov7pytorch: 100% [22232460 / 22232460] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carupRight10-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1362.27it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add up right patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carupright10\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add up right patch))\n",
        "!python test.py --data /content/yolov7/carupRight10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qyoB-6_qcxW",
        "outputId": "1297c0db-f809-4289-844f-907edf0269e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carupRight10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carupRight10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3308.12it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carupRight10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.72it/s]\n",
            "                 all         287         903       0.317       0.259       0.187      0.0695\n",
            "Speed: 14.2/1.4/15.6 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv_kfOaAu24k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbcef5d-5628-47d8-b310-7d175dc5c038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carupRight10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carupRight10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3205.99it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carupRight10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:08<00:00,  2.16it/s]\n",
            "                 all         287         903        0.79        0.64         0.7       0.453\n",
            "Speed: 14.4/2.4/16.7 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp28\n"
          ]
        }
      ],
      "source": [
        "#run trained (add up right patch)\n",
        "!python test.py --data /content/yolov7/carupRight10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u44ovxogvMdW"
      },
      "source": [
        "15 % Up Right Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSb_8yhYu2mm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9f6a74-4c9f-418a-b4dd-6961bb55e353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carupRight15-1 to yolov7pytorch: 100% [22220806 / 22220806] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carupRight15-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1664.17it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add up right patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carupright15\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add up right patch)\n",
        "!python test.py --data /content/yolov7/carupRight15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0buwRWyZqeSN",
        "outputId": "29fa8f5d-be0f-49fa-e95a-3833a4bf6337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carupRight15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carupRight15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3111.41it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carupRight15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.72it/s]\n",
            "                 all         287         903       0.328       0.302       0.202      0.0776\n",
            "Speed: 14.8/1.4/16.2 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFllgt36uLUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88c9d3b-a558-4236-8f11-890cf58d0b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carupRight15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carupRight15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3272.99it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carupRight15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.64it/s]\n",
            "                 all         287         903       0.826       0.667       0.732       0.484\n",
            "Speed: 14.1/1.5/15.6 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp27\n"
          ]
        }
      ],
      "source": [
        "#run trained (add up right patch)\n",
        "!python test.py --data /content/yolov7/carupRight15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IScQjs45vVmn"
      },
      "source": [
        "#Up Patch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRM5C8FJvecm"
      },
      "source": [
        "5 % Up Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHc-1XB3vTmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214a4df1-a54a-4707-da60-b2eb6b9f5483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carup5-1 to yolov7pytorch: 100% [22246462 / 22246462] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carup5-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1820.22it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add up patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carup5\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add up patch)\n",
        "!python test.py --data /content/yolov7/carup5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROlnLxhnqf_O",
        "outputId": "e8632009-80db-4465-d59b-33db7b1e20e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carup5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carup5-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3249.83it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carup5-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.73it/s]\n",
            "                 all         287         903       0.278       0.224       0.138      0.0465\n",
            "Speed: 14.2/1.7/15.9 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ3jGIhMvUMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13dbe05d-da44-4419-a66c-59336567f40f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carup5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carup5-1/valid/labels.cache' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.72it/s]\n",
            "                 all         287         903       0.752       0.476       0.543       0.348\n",
            "Speed: 13.9/1.6/15.5 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp23\n"
          ]
        }
      ],
      "source": [
        "#run trained (add up patch)\n",
        "!python test.py --data /content/yolov7/carup5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eRK06-Fvjcn"
      },
      "source": [
        "10 % Up Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ0_XbcTvUEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be357402-40ad-46b1-a689-b3cf4ecd590a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carup10-1 to yolov7pytorch: 100% [22248361 / 22248361] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carup10-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 2807.97it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add up patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carup10\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add up patch)\n",
        "!python test.py --data /content/yolov7/carup10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEwYuc1WqhUf",
        "outputId": "714db616-7b6f-4276-f0fb-7f7bc6f465f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carup10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carup10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3571.08it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carup10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:07<00:00,  2.46it/s]\n",
            "                 all         287         903       0.336       0.217       0.159       0.058\n",
            "Speed: 14.7/1.9/16.7 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33re97CDvUAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a055ce70-13d8-4f2c-bb19-944684eee60e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carup10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carup10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3294.85it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carup10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.83it/s]\n",
            "                 all         287         903       0.759       0.599       0.641       0.411\n",
            "Speed: 13.5/1.7/15.2 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp22\n"
          ]
        }
      ],
      "source": [
        "#run trained (add up patch)\n",
        "!python test.py --data /content/yolov7/carup10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DChfnLyvlo9"
      },
      "source": [
        "15 % Up Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8GmEWczvTxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "614588a4-b5bb-49c9-b724-91c3912581cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carup15-1 to yolov7pytorch: 100% [22252073 / 22252073] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carup15-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1015.26it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add up patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carup15\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add up patch)\n",
        "!python test.py --data /content/yolov7/carup15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDn6u4kAqiiO",
        "outputId": "5aaceb91-ccc9-4c23-8294-10fbb62f71ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carup15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carup15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3491.19it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carup15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.80it/s]\n",
            "                 all         287         903       0.338       0.259       0.185       0.069\n",
            "Speed: 14.2/1.4/15.6 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKcniMIfvn-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4043ec51-a919-4256-dbe7-bb1bd6a61dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carup15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carup15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3231.21it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carup15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.67it/s]\n",
            "                 all         287         903       0.775        0.63       0.671       0.439\n",
            "Speed: 14.0/1.4/15.5 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp26\n"
          ]
        }
      ],
      "source": [
        "#run trained (add up patch)\n",
        "!python test.py --data /content/yolov7/carup15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2oOAksBvqO9"
      },
      "source": [
        "#Up Left Patch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5NGuk_VvqIt"
      },
      "source": [
        "5 % Up Left Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbvVr_Uovoa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "096494b1-6927-42e2-d427-2b6d27a82f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carupleft5-1 to yolov7pytorch: 100% [22249498 / 22249498] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carupleft5-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1790.05it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add up left patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carupleft5\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add up left patch)\n",
        "!python test.py --data /content/yolov7/carupleft5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqUaEDN7qknt",
        "outputId": "5c65d321-f44f-4d21-fbaf-5125085a1cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carupleft5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carupleft5-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3418.23it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carupleft5-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.71it/s]\n",
            "                 all         287         903       0.278       0.212        0.14      0.0478\n",
            "Speed: 14.3/1.6/15.9 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebIY-NFDvoCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db2f3a2-a682-44b8-e702-8bd18ceb85e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carupleft5-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carupleft5-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 2411.05it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carupleft5-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.75it/s]\n",
            "                 all         287         903       0.731       0.515       0.559       0.352\n",
            "Speed: 13.9/1.5/15.5 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp25\n"
          ]
        }
      ],
      "source": [
        "#run trained (add up left patch)\n",
        "!python test.py --data /content/yolov7/carupleft5-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chgxqe14v6fc"
      },
      "source": [
        "10 % Up Left Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQp5iEPvv53-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c582531c-e21c-40bf-e5da-a838cb1e9486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carupleft10-1 to yolov7pytorch: 100% [22256259 / 22256259] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carupleft10-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1755.01it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add up left patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carupleft10\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add up left patch)\n",
        "!python test.py --data /content/yolov7/carupleft10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jlDA9qVqlxh",
        "outputId": "e040a17d-48ac-4458-9bb0-09afe05c2c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carupleft10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carupleft10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3026.67it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carupleft10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.70it/s]\n",
            "                 all         287         903       0.356       0.234       0.174      0.0666\n",
            "Speed: 14.3/1.7/15.9 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jBUDmflv50b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a870c952-c1f3-4939-ddb8-1c788ee15c89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carupleft10-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carupleft10-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3286.41it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carupleft10-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.69it/s]\n",
            "                 all         287         903       0.789       0.637       0.677       0.435\n",
            "Speed: 14.6/1.5/16.1 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp29\n"
          ]
        }
      ],
      "source": [
        "#run trained (add up left patch)\n",
        "!python test.py --data /content/yolov7/carupleft10-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO6KPtlUv8cz"
      },
      "source": [
        "15 % Up Left Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4vaX7dlv-Os",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f42b73d-8844-4797-a151-fdb8cb6b6c22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in carupleft15-1 to yolov7pytorch: 100% [22261508 / 22261508] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to carupleft15-1 in yolov7pytorch:: 100%|██████████| 580/580 [00:00<00:00, 1133.40it/s]\n"
          ]
        }
      ],
      "source": [
        "#import data (add up left patch)\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"8ScFpwTykHuXWHv6tirU\")\n",
        "project = rf.workspace(\"nida\").project(\"carupleft15\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run pre-train (add up left patch)\n",
        "!python test.py --data /content/yolov7/carupleft15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check01/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95hSOF7fqnQe",
        "outputId": "16934002-88d0-4b99-c185-c7ad6a71c11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carupleft15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check01/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carupleft15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3612.21it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carupleft15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:07<00:00,  2.27it/s]\n",
            "                 all         287         903       0.322       0.291       0.199      0.0753\n",
            "Speed: 14.8/2.2/17.0 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAVO1rdev-jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5812622-f412-432d-9f54-c7806871eb2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, conf_thres=0.01, data='/content/yolov7/carupleft15-1/data.yaml', device='0', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', no_trace=False, project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', v5_metric=False, verbose=False, weights=['/content/drive/MyDrive/project_deep/check8/weights/best.pt'])\n",
            "YOLOR 🚀 v0.1-121-g2fdc7f1 torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36481772 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'carupleft15-1/valid/labels' images and labels... 287 found, 0 missing, 0 empty, 0 corrupted: 100% 287/287 [00:00<00:00, 3324.56it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: carupleft15-1/valid/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 18/18 [00:06<00:00,  2.62it/s]\n",
            "                 all         287         903       0.804        0.66       0.709       0.463\n",
            "Speed: 14.4/1.6/15.9 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp30\n"
          ]
        }
      ],
      "source": [
        "#run trained (add up left patch)\n",
        "!python test.py --data /content/yolov7/carupleft15-1/data.yaml --img 640 --batch 16 --conf 0.01 --iou 0.65 --device 0 --weights /content/drive/MyDrive/project_deep/check8/weights/best.pt "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnjEderTSOaxwKzfG/W8ke",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}